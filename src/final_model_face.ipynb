{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Predictive Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T18:02:55.994945Z",
     "start_time": "2025-04-06T18:02:48.440201Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime, json, random, IPython, pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import matplotlib.image as mpimg\n",
    "import torch, pytorch_lightning as pl\n",
    "from ray import tune\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from models import GazeDataModule, SingleModel, EyesModel, FullModel\n",
    "from utils  import (\n",
    "    get_config,\n",
    "    tune_asha,\n",
    "    get_best_results,\n",
    "    save_model,\n",
    "    plot_asha_param_grid,\n",
    "    plot_parallel_param_loss,\n",
    "    latest_tune_dir,\n",
    "    _build_datamodule,\n",
    "    _build_model,\n",
    "    predict_screen_errors,\n",
    ")\n",
    "\n",
    "# project settings\n",
    "SETTINGS, COLOURS, EYETRACKER, TF = get_config(\"config.ini\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T18:02:56.009076Z",
     "start_time": "2025-04-06T18:02:56.000947Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/positions.csv\")\n",
    "region_map = np.load(\"data/region_map.npy\").T\n",
    "\n",
    "print(f\"# of samples: {len(df)}\")\n",
    "coverage = np.count_nonzero(region_map > 0) / region_map.size * 100\n",
    "print(f\"Coverage: {coverage:.2f}% of screen surface\")\n",
    "print(f\"Crop size: {SETTINGS['image_size']} x {SETTINGS['image_size']} px\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T18:02:58.998253Z",
     "start_time": "2025-04-06T18:02:58.186826Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.arange(region_map.shape[1])\n",
    "y = np.arange(region_map.shape[0])\n",
    "X, Y = np.meshgrid(x,y)\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "ax = fig.add_subplot(221)\n",
    "ax.hist(df['x'], bins=20, edgecolor='k')\n",
    "ax.set_title('Screen X')\n",
    "ax.margins(x=0)\n",
    "\n",
    "ax = fig.add_subplot(222, projection='3d')\n",
    "ax.dist = 9\n",
    "ax.plot_surface(X, Y, region_map, cmap=\"inferno\")\n",
    "ax.set_xlabel('Screen X', labelpad=-10)\n",
    "ax.set_ylabel('Screen Y', labelpad=-10)\n",
    "\n",
    "ax = fig.add_subplot(223)\n",
    "ax.imshow(region_map, interpolation='bilinear', cmap=\"inferno\")\n",
    "\n",
    "ax = fig.add_subplot(224)\n",
    "ax.hist(df['y'], bins=15, edgecolor='k', orientation='horizontal')\n",
    "ax.set_title('Screen Y')\n",
    "\n",
    "plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])\n",
    "plt.tight_layout()\n",
    "plt.savefig('media/images/0_data_distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T18:03:02.265245Z",
     "start_time": "2025-04-06T18:03:02.222105Z"
    }
   },
   "outputs": [],
   "source": [
    "low_bright  = plt.imread(\"data/r_eye/12.jpg\")\n",
    "high_bright = plt.imread(\"data/r_eye/31.jpg\")\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(6, 3))\n",
    "axs[0].imshow(low_bright);  axs[0].set_title(\"darker\")\n",
    "axs[1].imshow(high_bright); axs[1].set_title(\"brighter\")\n",
    "for ax in axs: ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T18:03:05.071626Z",
     "start_time": "2025-04-06T18:03:04.588690Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_calibration(eye: str):\n",
    "    idx = list(range(1, 10))\n",
    "    imgs = [plt.imread(f\"data/{eye}/{i}.jpg\") for i in idx]\n",
    "\n",
    "    fig, axs = plt.subplots(3, 3, figsize=(4, 4))\n",
    "    order = [3, 6, 8, 2, 4, 7, 1, 0, 5]  # keep your original layout\n",
    "    for ax, img_i in zip(axs.flat, order):\n",
    "        ax.imshow(imgs[img_i])\n",
    "        ax.axis(\"off\")\n",
    "    fig.suptitle(f\"9-point calibration: {eye}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"media/images/0_calibration_{eye}.png\", dpi=120)\n",
    "    plt.show()\n",
    "\n",
    "plot_calibration(\"l_eye\")\n",
    "plot_calibration(\"r_eye\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"seed\":  tune.randint(0, 10000),\n",
    "    \"bs\":    tune.choice([256, 512, 1024]),\n",
    "    \"lr\":    tune.loguniform(1e-4, 3e-3),\n",
    "    \"channels\": tune.choice([(32, 64, 128), (48, 96, 192), (64, 128, 256)]),\n",
    "    \"hidden\":   tune.choice([128, 256, 512]),\n",
    "}\n",
    "\n",
    "analysis = tune_asha(\n",
    "    search_space   = search_space,\n",
    "    train_func     = \"single\",  # utils infers correct trainer wrapper\n",
    "    name           = \"face/tune\",\n",
    "    img_types      = [\"face\"],\n",
    "    num_samples    = 20,\n",
    "    num_epochs     = 15,\n",
    "    data_dir     = Path.cwd() / \"data\",\n",
    "    seed           = 87,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_asha_param_grid(analysis, save_path=\"media/images/final_face_explore_scatter.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parallel_param_loss(analysis, save_path=\"media/images/final_face_explore_parallel.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now().strftime(\"%Y-%b-%d %H-%M-%S\")\n",
    "\n",
    "tune_dir = Path.cwd() / \"logs\" / \"face\"\n",
    "best_cfg = get_best_results(latest_tune_dir(tune_dir))\n",
    "pl.seed_everything(best_cfg[\"seed\"])\n",
    "\n",
    "dm = GazeDataModule(\n",
    "    data_dir = Path.cwd() / \"data\",\n",
    "    batch_size = best_cfg[\"bs\"],\n",
    "    img_types = [\"face\"],\n",
    "    seed = best_cfg[\"seed\"],\n",
    ")\n",
    "\n",
    "model = _build_model(best_cfg, [\"face\"])\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs = 100,\n",
    "    accelerator = \"auto\",\n",
    "    devices = \"auto\",\n",
    "    precision = \"bf16-mixed\",           # or \"16-mixed\" if your GPU supports it\n",
    "    logger = TensorBoardLogger(\n",
    "        save_dir = Path.cwd() / \"logs\",\n",
    "        name     = f\"face/final/{start_time}\",\n",
    "        log_graph = True,\n",
    "    ),\n",
    "    callbacks = [\n",
    "        pl.callbacks.ModelCheckpoint(\n",
    "            filename = \"best\",\n",
    "            monitor  = \"val_loss\",\n",
    "            mode     = \"min\",\n",
    "            save_last = True,\n",
    "            save_top_k = 1,\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "trainer.fit(model, datamodule=dm)\n",
    "best_path = trainer.checkpoint_callback.best_model_path\n",
    "state = torch.load(best_path, map_location=\"cpu\", weights_only=False)  # ←\n",
    "model.load_state_dict(state[\"state_dict\"])\n",
    "\n",
    "# save weights + config next to lightning checkpoint\n",
    "out_dir = Path.cwd() / \"logs\" / \"face\" / \"final\" / start_time\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "save_model(\n",
    "    model.cpu(),                   # save on CPU to shrink file size\n",
    "    best_cfg,\n",
    "    out_dir / \"eyetracking_model.pt\",\n",
    "    out_dir / \"eyetracking_config.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = trainer.test(ckpt_path=\"best\", datamodule=dm)[0]\n",
    "\n",
    "loss = test_results[\"test_loss_epoch\"]\n",
    "mae  = test_results[\"test_mae_epoch\"]\n",
    "\n",
    "mse  = test_results.get(\"test_mse_epoch\",  test_results.get(\"test_mse\"))\n",
    "rmse = test_results.get(\"test_rmse_epoch\", test_results.get(\"test_rmse\"))\n",
    "\n",
    "print(\"────────  Test set  ────────\")\n",
    "print(f\"MSE   : {mse:8.2f}  px²\")\n",
    "print(f\"RMSE  : {rmse:8.2f}  px\")\n",
    "print(f\"MAE   : {mae:8.2f}  px\")\n",
    "print(f\"Loss  : {loss:8.2f}  (Smooth-L1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_screen_errors(\n",
    "    \"face\",\n",
    "    path_model  = out_dir/\"eyetracking_model.pt\",\n",
    "    path_config = out_dir/\"eyetracking_config.json\",\n",
    "    path_plot   = out_dir/\"error_heatmap_face.png\",\n",
    "    path_errors = out_dir/\"errors.npy\",\n",
    "    steps       = 10,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

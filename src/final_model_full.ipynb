{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Predictive Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T18:02:55.994945Z",
     "start_time": "2025-04-06T18:02:48.440201Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime, json, random, IPython, pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import matplotlib.image as mpimg\n",
    "import torch, pytorch_lightning as pl\n",
    "from ray import tune\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from models import GazeDataModule, SingleModel, EyesModel, FullModel\n",
    "from utils  import (\n",
    "    get_config,\n",
    "    tune_asha,\n",
    "    get_best_results,\n",
    "    save_model,\n",
    "    plot_asha_param_grid,\n",
    "    plot_parallel_param_loss,\n",
    "    latest_tune_dir,\n",
    "    _build_datamodule,\n",
    "    _build_model,\n",
    "    predict_screen_errors,\n",
    ")\n",
    "\n",
    "# project settings\n",
    "SETTINGS, COLOURS, EYETRACKER, TF = get_config(\"config.ini\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix the \"Import 'mpimg' could not be resolved\" error, you need to install the `matplotlib` library, as `mpimg` is part of `matplotlib.image`. Use the `%pip install` magic command in Jupyter Notebook to install the required package.\n",
    "\n",
    "\n",
    "\n",
    "Made changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix the \"Import 'mpimg' could not be resolved\" error, you need to install the `matplotlib` library, as `mpimg` is part of `matplotlib.image`. Use the `%pip install` magic command in Jupyter Notebook to install the required package.\n",
    "\n",
    "\n",
    "\n",
    "Made changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T18:02:56.009076Z",
     "start_time": "2025-04-06T18:02:56.000947Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/positions.csv\")\n",
    "region_map = np.load(\"data/region_map.npy\").T\n",
    "\n",
    "print(f\"# of samples: {len(df)}\")\n",
    "coverage = np.count_nonzero(region_map > 0) / region_map.size * 100\n",
    "print(f\"Coverage: {coverage:.2f}% of screen surface\")\n",
    "print(f\"Crop size: {SETTINGS['image_size']} x {SETTINGS['image_size']} px\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"seed\":  tune.randint(0, 10000),\n",
    "    \"bs\":    tune.choice([64, 128, 256]),\n",
    "    \"lr\":    tune.loguniform(1e-4, 3e-3),\n",
    "    \"face_channels\"     : tune.choice([(32, 64, 128), (48, 96, 192)]),\n",
    "    \"eye_channels\"      : tune.choice([(32, 64, 128), (48, 96, 192)]),\n",
    "    \"head_pos_channels\" : tune.choice([(16, 32, 64),  (24, 48, 96)]),\n",
    "    \"hidden\": tune.choice([256, 512, 768]),\n",
    "}\n",
    "\n",
    "analysis = tune_asha(\n",
    "    search_space   = search_space,\n",
    "    train_func     = \"full\",\n",
    "    name           = \"full/tune\",\n",
    "    img_types    = [\"face_aligned\", \"l_eye\", \"r_eye\", \"head_pos\", \"head_angle\"],\n",
    "    num_samples    = 36,\n",
    "    num_epochs     = 15,\n",
    "    data_dir     = Path.cwd() / \"data\",\n",
    "    seed           = 87,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_asha_param_grid(\n",
    "    analysis,\n",
    "    params=(\"bs\", \"lr\",\n",
    "            \"face_channels\", \"eye_channels\", \"head_pos_channels\",\n",
    "            \"hidden\"),\n",
    "    save_path=\"media/images/final_full_explore_scatter.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parallel_param_loss(\n",
    "    analysis,\n",
    "    cols=(\"bs\", \"lr\",\n",
    "          \"face_channels\", \"eye_channels\", \"head_pos_channels\",\n",
    "          \"hidden\"),\n",
    "    save_path=\"media/images/final_full_explore_parallel.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now().strftime(\"%Y-%b-%d %H-%M-%S\")\n",
    "\n",
    "tune_dir = Path.cwd() / \"logs\" / \"full\"\n",
    "best_cfg = get_best_results(latest_tune_dir(tune_dir))\n",
    "pl.seed_everything(best_cfg[\"seed\"])\n",
    "\n",
    "dm = GazeDataModule(\n",
    "    data_dir = Path.cwd() / \"data\",\n",
    "    batch_size = best_cfg[\"bs\"],\n",
    "    img_types = [\"face_aligned\", \"l_eye\", \"r_eye\", \"head_pos\", \"head_angle\"],\n",
    "    seed = best_cfg[\"seed\"],\n",
    ")\n",
    "\n",
    "model = _build_model(best_cfg, [\n",
    "    \"face_aligned\", \"l_eye\", \"r_eye\", \"head_pos\", \"head_angle\"\n",
    "])\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs = 100,\n",
    "    accelerator = \"auto\",\n",
    "    devices = \"auto\",\n",
    "    precision = \"bf16-mixed\",\n",
    "    logger = TensorBoardLogger(\n",
    "        save_dir = Path.cwd() / \"logs\",\n",
    "        name     = f\"full/final/{start_time}\",\n",
    "        log_graph = True,\n",
    "    ),\n",
    "    callbacks = [\n",
    "        pl.callbacks.ModelCheckpoint(\n",
    "            filename = \"best\",\n",
    "            monitor  = \"val_loss\",\n",
    "            mode     = \"min\",\n",
    "            save_last = True,\n",
    "            save_top_k = 1,\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "trainer.fit(model, datamodule=dm)\n",
    "best_path = trainer.checkpoint_callback.best_model_path\n",
    "state = torch.load(best_path, map_location=\"cpu\", weights_only=False)\n",
    "model.load_state_dict(state[\"state_dict\"])\n",
    "\n",
    "out_dir = Path.cwd() / \"logs\" / \"full\" / \"final\" / start_time\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "save_model(\n",
    "    model.cpu(),\n",
    "    best_cfg,\n",
    "    out_dir / \"eyetracking_model.pt\",\n",
    "    out_dir / \"eyetracking_config.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = trainer.test(ckpt_path=\"best\", datamodule=dm)[0]\n",
    "\n",
    "loss = test_results[\"test_loss_epoch\"]\n",
    "mae  = test_results[\"test_mae_epoch\"]\n",
    "\n",
    "mse  = test_results.get(\"test_mse_epoch\",  test_results.get(\"test_mse\"))\n",
    "rmse = test_results.get(\"test_rmse_epoch\", test_results.get(\"test_rmse\"))\n",
    "\n",
    "print(\"────────  Test set  ────────\")\n",
    "print(f\"MSE   : {mse:8.2f}  px²\")\n",
    "print(f\"RMSE  : {rmse:8.2f}  px\")\n",
    "print(f\"MAE   : {mae:8.2f}  px\")\n",
    "print(f\"Loss  : {loss:8.2f}  (Smooth-L1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_screen_errors(\n",
    "    \"face_aligned\", \"l_eye\", \"r_eye\", \"head_pos\", \"head_angle\",\n",
    "    path_model  = out_dir/\"eyetracking_model.pt\",\n",
    "    path_config = out_dir/\"eyetracking_config.json\",\n",
    "    path_plot   = out_dir/\"error_heatmap_full.png\",\n",
    "    path_errors = out_dir/\"errors.npy\",\n",
    "    steps       = 10,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
